// å¤«å©¦ãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼Botï¼ˆå°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ï¼‹æ”¹è¡Œèª¿æ•´ä»˜ãï¼‰
const express = require('express');
const { Client, middleware } = require('@line/bot-sdk');
const { OpenAI } = require('openai');

const config = {
  channelAccessToken: process.env.CHANNEL_ACCESS_TOKEN,
  channelSecret: process.env.CHANNEL_SECRET,
};

const client = new Client(config);
const app = express();
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const userHistories = {}; // userIdã”ã¨ã®ä¼šè©±å±¥æ­´

const systemPrompt = `
ã‚ãªãŸã¯ã€å¤«å©¦é–¢ä¿‚ã‚„å­è‚²ã¦ã«é–¢ã™ã‚‹ç›¸è«‡ã‚’å—ã‘ã‚‹AIãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ°—æŒã¡ã‚’ä¸å¯§ã«æ•´ç†ã—ãªãŒã‚‰ã€çŠ¶æ³ã«å¿œã˜ã¦å°‚é–€çš„ãªè¦–ç‚¹ï¼ˆå¤«å©¦å¿ƒç†å­¦ã€ç™ºé”å¿ƒç†å­¦ã€è‚²å…æ–¹é‡ã®é•ã„ãªã©ï¼‰ã‚’é©åˆ‡ã«è£œè¶³ã—ã¦ãã ã•ã„ã€‚

ä¼šè©±ã®ç›®çš„ã¯ä»¥ä¸‹ã§ã™ï¼š
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã‚’æ˜Žç¢ºã«ã™ã‚‹
- ãã®èƒŒæ™¯ã«ã‚ã‚‹æœŸå¾…ã‚„ä¾¡å€¤è¦³ã‚’å¼•ãå‡ºã™
- ç›¸æ‰‹ã«ä¼ãˆã‚‹ã¹ãã“ã¨ãŒã‚ã‚‹å ´åˆã¯ã€ä¸€ç·’ã«ç¿»è¨³ã—ã¦ææ¡ˆã™ã‚‹

å‡ºåŠ›ã¯LINEãƒãƒ£ãƒƒãƒˆã§èª­ã¿ã‚„ã™ã„ã‚ˆã†ã€å¥èª­ç‚¹ã®å¾Œã‚„2ã€œ3æ–‡ã”ã¨ã«é©åº¦ãªæ”¹è¡Œã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚
å…±æ„Ÿãƒ»å®‰å¿ƒãƒ»ä¿¡é ¼ã‚’æ„Ÿã˜ã‚‰ã‚Œã‚‹ã‚ˆã†ã€ã‚ãŸãŸã‹ãã€ã¦ã„ã­ã„ãªæ–‡ä½“ã§è¿”ç­”ã—ã¦ãã ã•ã„ã€‚
`;

// æ”¹è¡Œæ•´å½¢ï¼ˆå¥ç‚¹ã®å¾Œã«æ”¹è¡Œï¼‰
function formatLineBreaks(text) {
  return text
    .replace(/([ã€‚ï¼ï¼Ÿ])(?=[^\n])/g, '$1\n')
    .replace(/\n{2,}/g, '\n');
}

// ã‚°ãƒ«ãƒ¼ãƒ—ãƒãƒ£ãƒƒãƒˆç”¨ï¼šOpenAIå¿œç­”ç”Ÿæˆï¼ˆdisplayNameãƒ™ãƒ¼ã‚¹ï¼‰
async function generateFacilitatedResponse(displayName, message) {
  const prompt = `${displayName}ã•ã‚“ãŒã€Œ${message}ã€ã¨è¨€ã„ã¾ã—ãŸã€‚\nå¤«å©¦é–“ã®å¯¾è©±ã‚’æ”¯æ´ã™ã‚‹AIãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼ã¨ã—ã¦ã€ç›¸æ‰‹ã«é…æ…®ã—ãŸè¿”ç­”ã‚’è‡ªç„¶ãªèªžã‚Šå£ã§è¡Œã£ã¦ãã ã•ã„ã€‚`;
  const response = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [
      { role: 'system', content: 'ã‚ãªãŸã¯å¤«å©¦ã®å¯¾è©±ã‚’æ”¯æ´ã™ã‚‹AIãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚å®‰å¿ƒæ„Ÿã¨æ¸©ã‹ã¿ã‚’ã‚‚ã£ã¦å¯¾è©±ã‚’é€²ã‚ã¦ãã ã•ã„ã€‚' },
      { role: 'user', content: prompt }
    ],
    temperature: 0.7,
  });
  return response.choices[0].message.content;
}

app.post('/webhook', middleware(config), async (req, res) => {
  const events = req.body.events;

  for (const event of events) {
    // ðŸ”¸ ã‚°ãƒ«ãƒ¼ãƒ—ãƒãƒ£ãƒƒãƒˆå¯¾å¿œãƒ–ãƒ­ãƒƒã‚¯
    if (event.type === 'message' && event.source.type === 'group') {
      const groupId = event.source.groupId;
      const userId = event.source.userId;
      const message = event.message.text.trim();

      try {
        const profile = await client.getGroupMemberProfile(groupId, userId);
        const displayName = profile.displayName;

        const aiReply = await generateFacilitatedResponse(displayName, message);
        const formatted = formatLineBreaks(aiReply);

        await client.replyMessage(event.replyToken, [
          { type: 'text', text: formatted }
        ]);
      } catch (err) {
        console.error('Group message error:', err);
      }
    }

    // ðŸ”¸ 1:1 ãƒãƒ£ãƒƒãƒˆå¯¾å¿œï¼ˆå¾“æ¥å‡¦ç†ï¼‰
    else if (event.type === 'message' && event.message.type === 'text') {
      const userId = event.source.userId;
      const message = event.message.text.trim();

      if (!userHistories[userId]) {
        userHistories[userId] = [
          { role: 'system', content: systemPrompt }
        ];
      }

      userHistories[userId].push({ role: 'user', content: message });

      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: userHistories[userId],
        temperature: 0.8,
      });

      const aiReply = response.choices[0].message.content;
      userHistories[userId].push({ role: 'assistant', content: aiReply });

      const formatted = formatLineBreaks(aiReply);
      await client.replyMessage(event.replyToken, [
        { type: 'text', text: formatted }
      ]);

      if (userHistories[userId].length > 20) {
        userHistories[userId].splice(1, 2);
      }
    }
  }

  res.sendStatus(200);
});

const port = process.env.PORT || 3000;
app.listen(port, () => console.log(`Server running on port ${port}`));
