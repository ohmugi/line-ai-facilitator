// å¤«å©¦ãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼Botï¼ˆå°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ï¼‹æ”¹è¡Œèª¿æ•´ä»˜ãï¼‰
const express = require('express');
const { Client, middleware } = require('@line/bot-sdk');
const { OpenAI } = require('openai');

const config = {
  channelAccessToken: process.env.CHANNEL_ACCESS_TOKEN,
  channelSecret: process.env.CHANNEL_SECRET,
};

const client = new Client(config);
const app = express();
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const userHistories = {}; // userIdã”ã¨ã®ä¼šè©±å±¥æ­´

const systemPrompt = `
ã‚ãªãŸã¯ã€å¤«å©¦é–¢ä¿‚ã‚„å­è‚²ã¦ã«é–¢ã™ã‚‹ç›¸è«‡ã‚’å—ã‘ã‚‹AIãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ°—æŒã¡ã‚’ä¸å¯§ã«æ•´ç†ã—ãªãŒã‚‰ã€çŠ¶æ³ã«å¿œã˜ã¦å°‚é–€çš„ãªè¦–ç‚¹ï¼ˆå¤«å©¦å¿ƒç†å­¦ã€ç™ºé”å¿ƒç†å­¦ã€è‚²å…æ–¹é‡ã®é•ã„ãªã©ï¼‰ã‚’é©åˆ‡ã«è£œè¶³ã—ã¦ãã ã•ã„ã€‚

ä¼šè©±ã®ç›®çš„ã¯ä»¥ä¸‹ã§ã™ï¼š
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã‚’æ˜Žç¢ºã«ã™ã‚‹
- ãã®èƒŒæ™¯ã«ã‚ã‚‹æœŸå¾…ã‚„ä¾¡å€¤è¦³ã‚’å¼•ãå‡ºã™
- ç›¸æ‰‹ã«ä¼ãˆã‚‹ã¹ãã“ã¨ãŒã‚ã‚‹å ´åˆã¯ã€ä¸€ç·’ã«ç¿»è¨³ã—ã¦ææ¡ˆã™ã‚‹

å‡ºåŠ›ã¯LINEãƒãƒ£ãƒƒãƒˆã§èª­ã¿ã‚„ã™ã„ã‚ˆã†ã€å¥èª­ç‚¹ã®å¾Œã‚„2ã€œ3æ–‡ã”ã¨ã«é©åº¦ãªæ”¹è¡Œã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚
å…±æ„Ÿãƒ»å®‰å¿ƒãƒ»ä¿¡é ¼ã‚’æ„Ÿã˜ã‚‰ã‚Œã‚‹ã‚ˆã†ã€ã‚ãŸãŸã‹ãã€ã¦ã„ã­ã„ãªæ–‡ä½“ã§è¿”ç­”ã—ã¦ãã ã•ã„ã€‚
`;

// æ”¹è¡Œæ•´å½¢ï¼ˆå¥ç‚¹ã®å¾Œã«æ”¹è¡Œï¼‰
function formatLineBreaks(text) {
  return text
    .replace(/([ã€‚ï¼ï¼Ÿ])(?=[^\n])/g, '$1\n')
    .replace(/\n{2,}/g, '\n');
}

// ------------------------------
// æ¡ä»¶åˆ†å²ï¼šæ©‹æ¸¡ã—ã‹æŽ˜ã‚Šä¸‹ã’ã‹
function decideFacilitationType(message) {
  const bridgeKeywords = [
    "å¯‚ã—ã„", "æ‚²ã—ã„", "å­¤ç‹¬", "ã¤ã‚‰ã„", "æ€’ã‚Š", "åˆ†ã‹ã£ã¦", "ã‚€ã‹ã¤ã", "æˆ‘æ…¢", "ç„¡è¦–", "å†·ãŸã„"
  ];
  const normalized = message.toLowerCase();

  for (const word of bridgeKeywords) {
    if (normalized.includes(word)) {
      return "bridge"; // æ©‹æ¸¡ã—ï¼ˆç›¸æ‰‹ã«å±Šã‘ã‚„ã™ãã™ã‚‹ï¼‰
    }
  }

  return "deepen"; // ãã‚Œä»¥å¤–ã¯æ·±æŽ˜ã‚Š
}

// ------------------------------
// æ·±æŽ˜ã‚Šï¼šæœ¬äººã®æ°—æŒã¡ãƒ»èƒŒæ™¯ã‚’æ•´ç†
async function generateDeepeningResponse(displayName, message) {
  const prompt = `
ã‚ãªãŸã¯ã€å¤«å©¦ã®å¯¾è©±ã‚’æ”¯æ´ã™ã‚‹AIãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã¯ã€ã‚°ãƒ«ãƒ¼ãƒ—ãƒãƒ£ãƒƒãƒˆã§${displayName}ã•ã‚“ãŒç™ºè¨€ã—ãŸå†…å®¹ã§ã™ã€‚

---
${displayName}ã•ã‚“ã®ç™ºè¨€ï¼š
ã€Œ${message}ã€
---

ã‚ãªãŸã®ç›®çš„ã¯ã€${displayName}ã•ã‚“ã®æ°—æŒã¡ã‚„è€ƒãˆã®å¥¥ã«ã‚ã‚‹ã€Œæœ¬éŸ³ã€ã‚„ã€ŒèƒŒæ™¯ã€ã‚’ä¸€ç·’ã«æŽ¢ã£ã¦ã„ãã“ã¨ã§ã™ã€‚

ä»¥ä¸‹ã®è¦ä»¶ã«æ²¿ã£ã¦ã€æ¸©ã‹ãã¦ä¸å¯§ãªè¿”ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

1. ${displayName}ã•ã‚“ã®ç™ºè¨€ã‚’ã—ã£ã‹ã‚Šå—ã‘æ­¢ã‚ãŸã†ãˆã§ã€ã©ã‚“ãªæ€ã„ã‚„çŠ¶æ³ãŒèƒŒæ™¯ã«ã‚ã‚‹ã®ã‹ã€ä¸€ç·’ã«è€ƒãˆã‚‹å•ã„ã‹ã‘ã‚’è¡Œã£ã¦ãã ã•ã„
2. æ„Ÿæƒ…ãƒ»å‡ºæ¥äº‹ãƒ»ä¾¡å€¤è¦³ãªã©ã€æ•´ç†ã—ã‚„ã™ã„æ–¹å‘æ€§ã‚’ç¤ºã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€Œã©ã‚“ãªçž¬é–“ã«ãã†æ„Ÿã˜ãŸã®ã‹ã€ã€Œä½•ãŒå¼•ã£ã‹ã‹ã£ã¦ã„ã‚‹ã®ã‹ã€ãªã©ï¼‰
3. æŠ¼ã—ã¤ã‘ã‚„è¨ºæ–­ã«ãªã‚‰ãªã„ã‚ˆã†ã«æ°—ã‚’ã¤ã‘ã¦ã€æ€ã„ã‚„ã‚Šã®ã‚ã‚‹è¨€è‘‰ã§ã‚„ã•ã—ãè¿”ã—ã¦ãã ã•ã„
`;

  const response = await openai.chat.completions.create({
    model: 'gpt-4o',
    messages: [
      { role: 'system', content: prompt }
    ],
    temperature: 0.7,
  });

  return response.choices[0].message.content;
}

// ------------------------------
// æ©‹æ¸¡ã—ï¼šç›¸æ‰‹ãŒç­”ãˆã‚„ã™ã„å½¢ã«æ•´ãˆã‚‹
async function generateFacilitatedResponse(displayName, message) {
  const prompt = `
ã‚ãªãŸã¯ã€å¤«å©¦é–“ã®ã‚°ãƒ«ãƒ¼ãƒ—ãƒãƒ£ãƒƒãƒˆã«å‚åŠ ã—ã¦ã„ã‚‹AIãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã¯ã€${displayName}ã•ã‚“ãŒãƒãƒ£ãƒƒãƒˆå†…ã§ç™ºè¨€ã—ãŸå†…å®¹ã§ã™ã€‚

---
${displayName}ã•ã‚“ã®ç™ºè¨€ï¼š
ã€Œ${message}ã€
---

ã‚ãªãŸã®å½¹å‰²ã¯ä»¥ä¸‹ã®3ã¤ã§ã™ï¼š

1. ${displayName}ã•ã‚“ã®è¨€è‘‰ã®èƒŒæ™¯ã«ã‚ã‚‹æœ¬éŸ³ãƒ»æ„Ÿæƒ…ã‚’ã€ä¸å¯§ã‹ã¤æ€ã„ã‚„ã‚Šã®ã‚ã‚‹è¨€è‘‰ã§ç¿»è¨³ãƒ»è¦ç´„ã—ã¦ãã ã•ã„
2. ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ãŒè¿”ç­”ã—ã‚„ã™ããªã‚‹ã‚ˆã†ã«ã€ã€Œã©ã®è¦–ç‚¹ã‹ã‚‰è¿”ã™ã¨å¯¾è©±ãŒå‰ã«é€²ã¿ã‚„ã™ã„ã‹ã€ã‚’1ã€œ2å€‹ã€å…·ä½“çš„ã«æç¤ºã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šè‡ªåˆ†ã®å—ã‘æ­¢ã‚æ–¹ï¼æ°—ã¥ã‘ã¦ã„ãªã‹ã£ãŸã“ã¨ï¼è‡ªåˆ†ã®è¡Œå‹•ã¸ã®æ°—ã¥ã ãªã©ï¼‰
3. èªžã‚Šå£ã¯ã€æ¸©ã‹ãè‡ªç„¶ä½“ã§ã€å®‰å¿ƒæ„Ÿã‚’ä¸Žãˆã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚ã€Œç„¡ç†ã«è¿”ã•ãªãã¦ã„ã„ã€ã¨ã„ã£ãŸé€ƒã’é“ã§ã¯ãªãã€è¿”ã—ã‚„ã™ã„é“ç­‹ã‚’ä½œã£ã¦ãã ã•ã„

â€»è¿”ç­”ã¯ã‚°ãƒ«ãƒ¼ãƒ—ãƒãƒ£ãƒƒãƒˆå†…ã§é€ä¿¡ã•ã‚Œã‚‹ãŸã‚ã€ç™ºè¨€è€…ã«è©±ã™ã®ã§ã¯ãªãã€ç¬¬ä¸‰è€…çš„ã«2äººã®é–¢ä¿‚æ€§ã‚’æ”¯ãˆã‚‹èªžã‚Šå£ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
`;

  const response = await openai.chat.completions.create({
    model: 'gpt-4',
    messages: [
      { role: 'system', content: prompt }
    ],
    temperature: 0.7,
  });

  return response.choices[0].message.content;
}

// ------------------------------
app.post('/webhook', middleware(config), async (req, res) => {
  const events = req.body.events;

  for (const event of events) {
    // ðŸ”¸ ã‚°ãƒ«ãƒ¼ãƒ—ãƒãƒ£ãƒƒãƒˆå¯¾å¿œãƒ–ãƒ­ãƒƒã‚¯
    if (event.type === 'message' && event.source.type === 'group') {
      const groupId = event.source.groupId;
      const userId = event.source.userId;
      const message = event.message.text.trim();

      try {
        const profile = await client.getGroupMemberProfile(groupId, userId);
        const displayName = profile.displayName;

        const mode = decideFacilitationType(message);
        const aiReply = (mode === 'bridge')
          ? await generateFacilitatedResponse(displayName, message)
          : await generateDeepeningResponse(displayName, message);

        const formatted = formatLineBreaks(aiReply);
        await client.replyMessage(event.replyToken, [
          { type: 'text', text: formatted }
        ]);
      } catch (err) {
        console.error('Group message error:', err);
      }
    }

    // ðŸ”¸ 1:1 ãƒãƒ£ãƒƒãƒˆå¯¾å¿œï¼ˆå¾“æ¥å‡¦ç†ï¼‰
    else if (event.type === 'message' && event.message.type === 'text') {
      const userId = event.source.userId;
      const message = event.message.text.trim();

      if (!userHistories[userId]) {
        userHistories[userId] = [
          { role: 'system', content: systemPrompt }
        ];
      }

      userHistories[userId].push({ role: 'user', content: message });

      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: userHistories[userId],
        temperature: 0.8,
      });

      const aiReply = response.choices[0].message.content;
      userHistories[userId].push({ role: 'assistant', content: aiReply });

      const formatted = formatLineBreaks(aiReply);
      await client.replyMessage(event.replyToken, [
        { type: 'text', text: formatted }
      ]);

      if (userHistories[userId].length > 20) {
        userHistories[userId].splice(1, 2);
      }
    }
  }

  res.sendStatus(200);
});

const port = process.env.PORT || 3000;
app.listen(port, () => console.log(`Server running on port ${port}`));
